{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bct\n",
    "import copy\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "from atlases import DesikanAtlas\n",
    "from hmmlearn import hmm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Dimensional Connectome Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data - Separate Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17906, 68, 68)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_all_trials_connectomes = utils.load_connectomes(utils.ALL_SUBJECT_IDS, utils.ALL_TRIAL_IDS)\n",
    "all_subjects_all_trials_connectomes['fmri'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract flattened representation of upper triangular of Pearson correlation matrix for each connectome type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: The below logic would have to change if we move away from using Desikan Atlas where the number of regions \n",
    "# are the same between EEG and fMRI\n",
    "num_regions = all_subjects_all_trials_connectomes['fmri'].shape[1]\n",
    "num_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangular_including_diagonal_idxs = np.triu_indices(num_regions, k=0)\n",
    "lower_triangular_idxs = np.tril_indices(num_regions, k=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects_all_trials_connectome_upper_triangular_flattened = copy.deepcopy(all_subjects_all_trials_connectomes)\n",
    "for k in all_subjects_all_trials_connectome_upper_triangular_flattened:\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened[k] = np.array([c[upper_triangular_including_diagonal_idxs].flatten() for c in all_subjects_all_trials_connectomes[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17906, 2346)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects_all_trials_connectome_upper_triangular_flattened['fmri'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data - Combined Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_matrix_from_channels(channels):\n",
    "    data_matrix = []\n",
    "    for k in channels:\n",
    "        data_matrix.append(all_subjects_all_trials_connectome_upper_triangular_flattened[k])\n",
    "    data_matrix = np.concatenate(data_matrix, axis=1)\n",
    "    return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta_delta_gamma_theta_matrix = data_matrix_from_channels(['alpha', 'beta', 'delta', 'gamma', 'theta'])\n",
    "fmri_alpha_beta_delta_gamma_theta_matrix = data_matrix_from_channels(['fmri', 'alpha', 'beta', 'delta', 'gamma', 'theta'])\n",
    "fmri_broad_matrix = data_matrix_from_channels(['fmri', 'broad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features_per_modality = all_subjects_all_trials_connectome_upper_triangular_flattened['fmri'].shape[1]\n",
    "# fmri_feature_idxs  = range(num_features_per_modality*0, num_features_per_modality*1)\n",
    "# alpha_feature_idxs = range(num_features_per_modality*1, num_features_per_modality*2)\n",
    "# beta_feature_idxs  = range(num_features_per_modality*2, num_features_per_modality*3)\n",
    "# delta_feature_idxs = range(num_features_per_modality*3, num_features_per_modality*4)\n",
    "# gamma_feature_idxs = range(num_features_per_modality*4, num_features_per_modality*5)\n",
    "# theta_feature_idxs = range(num_features_per_modality*5, num_features_per_modality*6)\n",
    "\n",
    "# feature_idxs = [('fmri', fmri_feature_idxs),\n",
    "#                 ('alpha', alpha_feature_idxs),\n",
    "#                 ('beta', beta_feature_idxs),\n",
    "#                 ('delta', delta_feature_idxs),\n",
    "#                 ('gamma', gamma_feature_idxs),\n",
    "#                 ('theta', theta_feature_idxs)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) TODO: Find a bunch of graph statistics (node-wise or global) and compute the time series of the graph statistics and fit an HMM to that.\n",
    "\n",
    "(2) TODO: Train HMMs on subset of data and predict likelihood of new data\n",
    "\n",
    "(3) TODO: Align states between modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_parameters_in_hmm(model):  \n",
    "    k = model.means_.shape[0]\n",
    "    d = model.means_.shape[1]\n",
    "    # NOTE: We are using a diagonal covariance matrix\n",
    "    return (k*d)+(k*d)+k+(k**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_optimal_hmm_on_data(data, bic=True, pca_variance_retained=0.99, forced_component_count=None):\n",
    "    \n",
    "    # Apply PCA to dimensionality reduce the data and retain xx% variance\n",
    "    print(\"\\tApplying pca and retaining {0:.2f}% variance...\".format(pca_variance_retained*100))\n",
    "    pca_model = PCA(pca_variance_retained)\n",
    "    dim_reduced_data = pca_model.fit_transform(data)\n",
    "    print(\"\\t{0} dimensions -> {1} dimensions\".format(data.shape[1], dim_reduced_data.shape[1]))\n",
    "    \n",
    "    # Compute BIC/AIC scores for HMM models with # states between 1 and N-1\n",
    "    scores = []\n",
    "    candidate_hmm_models = []\n",
    "    \n",
    "    for n_components in (range(2, data.shape[0]-1) if not forced_component_count else range(forced_component_count, forced_component_count+1)):\n",
    "        \n",
    "        print(\"\\t\\t training hmm with n_components={0}\".format(n_components))\n",
    "\n",
    "        # Train HMM model\n",
    "        candidate_hmm_model = hmm.GaussianHMM(n_components=n_components,\n",
    "                                              covariance_type=\"diag\").fit(dim_reduced_data)\n",
    "        candidate_hmm_models.append(candidate_hmm_model)\n",
    "\n",
    "        # Compute BIC/AIC score\n",
    "        n = dim_reduced_data.shape[0]\n",
    "        k = num_parameters_in_hmm(candidate_hmm_model)\n",
    "        L = candidate_hmm_model.decode(dim_reduced_data)[0]\n",
    "\n",
    "        print(\"\\t\\t\\tn={0}, k={1}, L={2}\".format(n, k, L))\n",
    "\n",
    "        score = (np.log(n)*k - 2*L) if bic else (k - L)\n",
    "        scores.append(score)\n",
    "        print(\"\\t\\t\\tScore={0}\".format(score))\n",
    "        \n",
    "        if len(scores) >= 3:\n",
    "            # Last two increases in number of components yielded worse scores -> exit search\n",
    "            if scores[-1] > scores[-3] and scores[-2] > scores[-3]:\n",
    "                break\n",
    "    \n",
    "    # Select the model with the lowest BIC/AIC score\n",
    "    selected_hmm_model = candidate_hmm_models[np.argmin(scores)]\n",
    "    return selected_hmm_model, pca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_optimal_hmms_together(data_channels, bic=True, pca_variance_retained=0.99):\n",
    "    \n",
    "    # Apply PCA to dimensionality reduce the data and retain xx% variance\n",
    "    print(\"\\tApplying pca and retaining {0:.2f}% variance...\".format(pca_variance_retained*100))\n",
    "    pca_models = []\n",
    "    dim_reduced_data_channels = []\n",
    "    \n",
    "    for data in data_channels:\n",
    "        pca_model = PCA(pca_variance_retained)\n",
    "        dim_reduced_data = pca_model.fit_transform(data)\n",
    "        \n",
    "        pca_models.append(pca_model)\n",
    "        dim_reduced_data_channels.append(dim_reduced_data)\n",
    "        print(\"\\t{0} dimensions -> {1} dimensions\".format(data.shape[1], dim_reduced_data.shape[1]))\n",
    "    \n",
    "    # Compute BIC/AIC scores for HMM models with # states between 1 and N-1\n",
    "    scores = []\n",
    "    candidate_hmm_models = []\n",
    "    \n",
    "    for n_components in range(2, len(data_channels[0])-1):\n",
    "        \n",
    "        print(\"\\t\\t training hmms with n_components={0}\".format(n_components))\n",
    "\n",
    "        # Train HMM model for every data channel\n",
    "        candidate_hmm_models_with_n_components = []\n",
    "        scores_with_n_components = []\n",
    "        for dim_reduced_data in dim_reduced_data_channels:\n",
    "            candidate_hmm_model = hmm.GaussianHMM(n_components=n_components,\n",
    "                                                  covariance_type=\"diag\").fit(dim_reduced_data)\n",
    "            candidate_hmm_models_with_n_components.append(candidate_hmm_model)\n",
    "            \n",
    "            # Compute BIC/AIC score\n",
    "            n = dim_reduced_data.shape[0]\n",
    "            k = num_parameters_in_hmm(candidate_hmm_model)\n",
    "            L = candidate_hmm_model.decode(dim_reduced_data)[0]\n",
    "\n",
    "            print(\"\\t\\t\\t\\tn={0}, k={1}, L={2}\".format(n, k, L))\n",
    "\n",
    "            score = (np.log(n)*k - 2*L) if bic else (k - L)\n",
    "            scores_with_n_components.append(score)\n",
    "            print(\"\\t\\t\\t\\t\\t=> Score={0}\".format(score))\n",
    "        \n",
    "        candidate_hmm_models.append(candidate_hmm_models_with_n_components)\n",
    "        scores.append(np.mean(scores_with_n_components))\n",
    "        print(\"\\t\\t\\tScore={0}\".format(scores[-1]))\n",
    "\n",
    "\n",
    "        if len(scores) >= 3:\n",
    "            # Last two increases in number of components yielded worse scores -> exit search\n",
    "            if scores[-1] > scores[-3] and scores[-2] > scores[-3]:\n",
    "                break\n",
    "                \n",
    "    # Select the model with the lowest BIC/AIC score\n",
    "    selected_hmm_models = candidate_hmm_models[np.argmin(scores)]\n",
    "    return selected_hmm_models, pca_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMBINED EEG BANDS (Alpha+Beta+Delta+Gamma+Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_alpha_beta_delta_gamma_theta_hmm_model = joblib.load(\"output/hmm/models/[hmm]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))\n",
    "combined_alpha_beta_delta_gamma_theta_pca_model = joblib.load(\"output/hmm/models/[pca]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined_alpha_beta_delta_gamma_theta_hmm_model, combined_alpha_beta_delta_gamma_theta_pca_model = train_optimal_hmm_on_data(all_eeg_bands_all_subjects_all_trials_connectome_upper_triangular_flattened, pca_variance_retained=0.9)\n",
    "joblib.dump(combined_alpha_beta_delta_gamma_theta_hmm_model, \"output/hmm/models/[hmm]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))\n",
    "joblib.dump(combined_alpha_beta_delta_gamma_theta_pca_model, \"output/hmm/models/[pca]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMBINED EEG BANDS (Broad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_hmm_model = joblib.load(\"output/hmm/models/[hmm]-[broad].pkl\")\n",
    "broad_pca_model = joblib.load(\"output/hmm/models/[pca]-[broad].pkl\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "broad_hmm_model, broad_pca_model = train_optimal_hmm_on_data(all_subjects_all_trials_connectome_upper_triangular_flattened['broad'],\n",
    "                                                             pca_variance_retained=0.9)\n",
    "joblib.dump(broad_hmm_model, \"output/hmm/models/[hmm]-[broad].pkl\")\n",
    "joblib.dump(broad_pca_model, \"output/hmm/models/[pca]-[broad].pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  COMBINED MODALITY HMM MODEL (fMRI+Alpha+Beta+Delta+Gamma+Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fmri_alpha_beta_delta_gamma_theta_hmm_model = joblib.load(\"output/hmm/models/[hmm]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))\n",
    "combined_fmri_alpha_beta_delta_gamma_theta_pca_model = joblib.load(\"output/hmm/models/[pca]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined_fmri_alpha_beta_delta_gamma_theta_hmm_model, combined_fmri_alpha_beta_delta_gamma_theta_pca_model = train_optimal_hmm_on_data(fmri_alpha_beta_delta_gamma_theta_matrix, pca_variance_retained=0.90)\n",
    "joblib.dump(combined_fmri_alpha_beta_delta_gamma_theta_hmm_model, \"output/hmm/models/[hmm]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))\n",
    "joblib.dump(combined_fmri_alpha_beta_delta_gamma_theta_pca_model, \"output/hmm/models/[pca]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(\"combined\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  COMBINED MODALITY HMM MODEL (fMRI+Broad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fmri_broad_hmm_model = joblib.load(\"output/hmm/models/[hmm]-[fmri_broad]-[{0}].pkl\".format(\"combined\"))\n",
    "combined_fmri_broad_pca_model = joblib.load(\"output/hmm/models/[pca]-[fmri_broad]-[{0}].pkl\".format(\"combined\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined_fmri_broad_hmm_model, combined_fmri_broad_pca_model = train_optimal_hmm_on_data(fmri_broad_matrix, pca_variance_retained=0.90)\n",
    "joblib.dump(combined_fmri_broad_hmm_model, \"output/hmm/models/[hmm]-[fmri_broad]-[{0}].pkl\".format(\"combined\"))\n",
    "joblib.dump(combined_fmri_broad_pca_model, \"output/hmm/models/[pca]-[fmri_broad]-[{0}].pkl\".format(\"combined\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEPARATE EEG BANDS (Alpha+Beta+Delta+Gamma+Theta HMMs Trained Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta_delta_gamma_theta_hmm_models = [joblib.load(\"output/hmm/models/[hmm]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k)) for k in ['alpha', 'beta', 'delta', 'gamma', 'theta']]\n",
    "alpha_beta_delta_gamma_theta_pca_models = [joblib.load(\"output/hmm/models/[pca]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k)) for k in ['alpha', 'beta', 'delta', 'gamma', 'theta']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "alpha_beta_delta_gamma_theta_hmm_models, alpha_beta_delta_gamma_theta_pca_models = train_optimal_hmms_together([\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['alpha'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['beta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['delta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['gamma'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['theta']\n",
    "], pca_variance_retained=0.9)\n",
    "\n",
    "for k, hmm_model, pca_model in zip(['alpha', 'beta', 'delta', 'gamma', 'theta'], alpha_beta_delta_gamma_theta_hmm_models, alpha_beta_delta_gamma_theta_pca_models):\n",
    "    joblib.dump(hmm_model, \"output/hmm/models/[hmm]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k))\n",
    "    joblib.dump(pca_model, \"output/hmm/models/[pca]-[alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEPARATE MODALITIES (fMRI+Alpha+Beta+Delta+Gamma+Theta HMMs Trained Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_alpha_beta_delta_gamma_theta_pca_models = []\n",
    "fmri_alpha_beta_delta_gamma_theta_hmm_models = []\n",
    "\n",
    "for k in ['fmri', 'alpha', 'beta', 'delta', 'gamma', 'theta']:\n",
    "    fmri_alpha_beta_delta_gamma_theta_pca_models.append(joblib.load(\"output/hmm/models/[pca]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k)))\n",
    "    fmri_alpha_beta_delta_gamma_theta_hmm_models.append(joblib.load(\"output/hmm/models/[hmm]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fmri_alpha_beta_delta_gamma_theta_hmm_models, fmri_alpha_beta_delta_gamma_theta_pca_models = train_optimal_hmms_together([\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['fmri'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['alpha'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['beta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['delta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['gamma'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['theta']\n",
    "], pca_variance_retained=0.9)\n",
    "\n",
    "for k, hmm_model, pca_model in zip(['fmri', 'alpha', 'beta', 'delta', 'gamma', 'theta'], fmri_alpha_beta_delta_gamma_theta_hmm_models, fmri_alpha_beta_delta_gamma_theta_pca_models):\n",
    "    joblib.dump(hmm_model, \"output/hmm/models[hmm]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k))\n",
    "    joblib.dump(pca_model, \"output/hmm/models/[pca]-[fmri_alpha_beta_delta_gamma_theta]-[{0}].pkl\".format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEPARATE MODALITIES (fMRI+Broad HMMs Trained Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_broad_pca_models = []\n",
    "fmri_broad_hmm_models = []\n",
    "\n",
    "for k in ['fmri', 'broad']:\n",
    "    fmri_broad_pca_models.append(joblib.load(\"output/hmm/models/[pca]-[fmri_broad]-[{0}].pkl\".format(k)))\n",
    "    fmri_broad_hmm_models.append(joblib.load(\"output/hmm/models/[hmm]-[fmri_broad]-[{0}].pkl\".format(k)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fmri_broad_hmm_models, fmri_broad_pca_models = train_optimal_hmms_together([\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['fmri'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['broad'],\n",
    "], pca_variance_retained=0.9)\n",
    "\n",
    "for k, hmm_model, pca_model in zip(['fmri', 'broad'], fmri_broad_hmm_models, fmri_broad_pca_models):\n",
    "    joblib.dump(hmm_model, \"output/hmm/models/[hmm]-[fmri_broad]-[{0}].pkl\".format(k))\n",
    "    joblib.dump(pca_model, \"output/hmm/models/[pca]-[fmri_broad]-[{0}].pkl\".format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoded Hidden State Sequence Likelihood Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMBINED EEG BANDS (Alpha+Beta+Delta+Gamma+Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_alpha_beta_delta_gamma_theta_hmm_model.means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82461646.03284961"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_alpha_beta_delta_gamma_theta_log_likelihood, combined_alpha_beta_delta_gamma_theta_decoded_state_sequence = combined_alpha_beta_delta_gamma_theta_hmm_model.decode(combined_alpha_beta_delta_gamma_theta_pca_model.transform(alpha_beta_delta_gamma_theta_matrix))\n",
    "combined_alpha_beta_delta_gamma_theta_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMBINED EEG BANDS (Broad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broad_hmm_model.means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40006049.92391768"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broad_log_likelihood, broad_decoded_state_sequence = broad_hmm_model.decode(broad_pca_model.transform(all_subjects_all_trials_connectome_upper_triangular_flattened['broad']))\n",
    "broad_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMBINED MODALITIES (fMRI+Alpha+Beta+Delta+Gamma+Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_fmri_alpha_beta_delta_gamma_theta_hmm_model.means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2309626.5700253514"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_fmri_alpha_beta_delta_gamma_theta_log_likelihood, combined_fmri_alpha_beta_delta_gamma_theta_decoded_state_sequence = combined_fmri_alpha_beta_delta_gamma_theta_hmm_model.decode(combined_fmri_alpha_beta_delta_gamma_theta_pca_model.transform(fmri_alpha_beta_delta_gamma_theta_matrix))\n",
    "combined_fmri_alpha_beta_delta_gamma_theta_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  COMBINED MODALITIES (fMRI+Broad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_fmri_broad_hmm_model.means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6776413.256126671"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_fmri_broad_log_likelihood, combined_fmri_broad_decoded_state_sequence = combined_fmri_broad_hmm_model.decode(combined_fmri_broad_pca_model.transform(fmri_broad_matrix))\n",
    "combined_fmri_broad_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEPARATE EEG BANDS (Alpha+Beta+Delta+Gamma+Theta HMMs Trained Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta_delta_gamma_theta_hmm_models[0].means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta_delta_gamma_theta_decoded_state_sequences = []\n",
    "alpha_beta_delta_gamma_theta_decoded_log_likelihoods = []\n",
    "alpha_beta_delta_gamma_theta_data_channels = [\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['alpha'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['beta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['delta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['gamma'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['theta']\n",
    "]\n",
    "for (data_channel, hmm_model, pca_model) in zip(alpha_beta_delta_gamma_theta_data_channels, alpha_beta_delta_gamma_theta_hmm_models, alpha_beta_delta_gamma_theta_pca_models):\n",
    "    dim_reduced_data = pca_model.transform(data_channel)\n",
    "    decoded_state_sequence = hmm_model.decode(dim_reduced_data)\n",
    "    alpha_beta_delta_gamma_theta_decoded_log_likelihoods.append(decoded_state_sequence[0])\n",
    "    alpha_beta_delta_gamma_theta_decoded_state_sequences.append(decoded_state_sequence[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25168602.111413915, 37566808.92075627, 26784010.713776994, 28916582.493297048, 25957636.951635607]\n",
      "28878728.238175966\n"
     ]
    }
   ],
   "source": [
    "print(alpha_beta_delta_gamma_theta_decoded_log_likelihoods)\n",
    "print(np.mean(alpha_beta_delta_gamma_theta_decoded_log_likelihoods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEPARATE MODALITIES (fMRI+Alpha+Beta+Delta+Gamma+Theta HMMs Trained Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_alpha_beta_delta_gamma_theta_hmm_models[0].means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_alpha_beta_delta_gamma_theta_decoded_state_sequences = []\n",
    "fmri_alpha_beta_delta_gamma_theta_decoded_log_likelihoods = []\n",
    "fmri_alpha_beta_delta_gamma_theta_data_channels = [\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['fmri'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['alpha'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['beta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['delta'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['gamma'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['theta']\n",
    "]\n",
    "for (data_channel, hmm_model, pca_model) in zip(fmri_alpha_beta_delta_gamma_theta_data_channels, fmri_alpha_beta_delta_gamma_theta_hmm_models, fmri_alpha_beta_delta_gamma_theta_pca_models):\n",
    "    dim_reduced_data = pca_model.transform(data_channel)\n",
    "    decoded_state_sequence = hmm_model.decode(dim_reduced_data)\n",
    "    fmri_alpha_beta_delta_gamma_theta_decoded_log_likelihoods.append(decoded_state_sequence[0])\n",
    "    fmri_alpha_beta_delta_gamma_theta_decoded_state_sequences.append(decoded_state_sequence[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7404563.869950348, 25168736.860782143, 37566920.50689304, 26777941.281714328, 28916600.5088779, 25957892.799562633]\n",
      "22830588.014646616\n"
     ]
    }
   ],
   "source": [
    "print(fmri_alpha_beta_delta_gamma_theta_decoded_log_likelihoods)\n",
    "print(np.mean(fmri_alpha_beta_delta_gamma_theta_decoded_log_likelihoods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SEPARATE MODALITIES (fMRI+Broad HMMs Trained Together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_broad_hmm_models[0].means_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_broad_decoded_state_sequences = []\n",
    "fmri_broad_decoded_log_likelihoods = []\n",
    "fmri_broad_data_channels = [\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['fmri'],\n",
    "    all_subjects_all_trials_connectome_upper_triangular_flattened['broad'],\n",
    "]\n",
    "for (data_channel, hmm_model, pca_model) in zip(fmri_broad_data_channels, fmri_broad_hmm_models, fmri_broad_pca_models):\n",
    "    dim_reduced_data = pca_model.transform(data_channel)\n",
    "    decoded_state_sequence = hmm_model.decode(dim_reduced_data)\n",
    "    fmri_broad_decoded_log_likelihoods.append(decoded_state_sequence[0])\n",
    "    fmri_broad_decoded_state_sequences.append(decoded_state_sequence[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7172960.976526341, 40144751.55825858]\n",
      "16485895.290866118\n"
     ]
    }
   ],
   "source": [
    "print(fmri_broad_decoded_log_likelihoods)\n",
    "print(np.mean(fmri_broad_decoded_log_likelihoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Representation of Hidden States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPARATE MODALTIES - Plot spatial representation of each hidden markov model state in connectome space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(180, 60))\n",
    "fig.suptitle('Spatial Loadings of Hidden Markov Model States', fontsize=40)\n",
    "\n",
    "num_states_to_plot = 5\n",
    "subplot_idx = 1\n",
    "for (k, hmm_model, pca_model) in zip(all_subjects_all_trials_connectome_upper_triangular_flattened, hmm_models, hmm_preprocessing_pca_models):\n",
    "    for state_idx in range(0, num_states_to_plot):\n",
    "        \n",
    "        if hmm_model.means_.shape[0] <= state_idx:\n",
    "            ax = fig.add_subplot(len(hmm_models), num_states_to_plot, subplot_idx)\n",
    "            subplot_idx += 1\n",
    "            continue\n",
    "\n",
    "        # Extract connectome representation of the hidden state\n",
    "        hidden_state = np.zeros((num_regions, num_regions))\n",
    "        hidden_state[upper_triangular_including_diagonal_idxs] = np.matmul(hmm_model.means_[state_idx], pca_model.components_)\n",
    "        hidden_state[lower_triangular_idxs] = hidden_state.T[lower_triangular_idxs]\n",
    "\n",
    "        # Plot connectome representation of the hidden state\n",
    "        ax = fig.add_subplot(len(hmm_models), num_states_to_plot, subplot_idx)\n",
    "        DesikanAtlas.plot(connectome=hidden_state,\n",
    "                          title='{0} HiddenState-{1} Connectome'.format(k, state_idx+1),\n",
    "                          axes=ax)\n",
    "        subplot_idx += 1\n",
    "\n",
    "plt.savefig('output/hmm/spatial_loadings.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINED MODALITIES - Plot spatial representation of each hidden markov model state in connectome space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(180, 60))\n",
    "fig.suptitle('Spatial Loadings of Combined Hidden Markov Model States', fontsize=40)\n",
    "\n",
    "num_states_to_plot = min(5, combined_modality_hmm_model.means_.shape[0])\n",
    "subplot_idx = 1\n",
    "for feature_desc, feature_idx in feature_idxs:\n",
    "    for state_idx in range(num_states_to_plot):\n",
    "        \n",
    "        # Extract connectome representation of the hidden state\n",
    "        hidden_state = np.zeros((num_regions, num_regions))\n",
    "        hidden_state[upper_triangular_including_diagonal_idxs] = np.matmul(combined_modality_hmm_model.means_[state_idx], combined_modality_preprocessing_pca_model.components_)[feature_idx]\n",
    "        hidden_state[lower_triangular_idxs] = hidden_state.T[lower_triangular_idxs]\n",
    "\n",
    "        # Plot connectome representation of the hidden state\n",
    "        ax = fig.add_subplot(len(feature_idxs), num_states_to_plot, subplot_idx)\n",
    "        DesikanAtlas.plot(connectome=hidden_state,\n",
    "                          title='{0} HiddenState-{1} Connectome'.format(feature_desc, state_idx+1),\n",
    "                          axes=ax)\n",
    "        subplot_idx += 1\n",
    "\n",
    "plt.savefig('output/hmm/combined_modality_spatial_loadings.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoded Hidden State Sequence Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot fractional occupancy - the fraction of time spent in each state relative to the total duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARATE\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "fig.suptitle('Fractional Occupancy')\n",
    "num_plots = len(decoded_state_sequences)\n",
    "subplot_idx = 1\n",
    "\n",
    "for (k, hmm_model, state_seq) in zip(all_subjects_all_trials_connectome_upper_triangular_flattened, hmm_models, decoded_state_sequences):\n",
    "    \n",
    "    # Compute fractional occupancy\n",
    "    fractional_occupancies_per_state = []\n",
    "    for state_idx in range(0, hmm_model.means_.shape[0]):\n",
    "        fractional_occupancy = len(state_seq[state_seq == state_idx])/len(state_seq)\n",
    "        fractional_occupancies_per_state.append(fractional_occupancy)\n",
    "        \n",
    "    # Plot fractional occupancy per state\n",
    "    fig.add_subplot(1, num_plots, subplot_idx)\n",
    "    plt.title(k)\n",
    "    x = np.arange(hmm_model.means_.shape[0])\n",
    "    plt.bar(x, height=fractional_occupancies_per_state)\n",
    "    plt.xticks(x, [str(x_i) for x_i in x])\n",
    "    subplot_idx += 1\n",
    "    \n",
    "plt.savefig('output/hmm/fractional_occupancy.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED\n",
    "# Compute fractional occupancy\n",
    "fractional_occupancies_per_state = []\n",
    "for state_idx in range(0, combined_modality_hmm_model.means_.shape[0]):\n",
    "    fractional_occupancy = len(combined_modality_decoded_state_sequence[combined_modality_decoded_state_sequence == state_idx])/len(combined_modality_decoded_state_sequence)\n",
    "    fractional_occupancies_per_state.append(fractional_occupancy)\n",
    "\n",
    "# Plot fractional occupancy per state\n",
    "plt.title('Combined Fractional Occupancy')\n",
    "x = np.arange(combined_modality_hmm_model.means_.shape[0])\n",
    "plt.bar(x, height=fractional_occupancies_per_state)\n",
    "plt.xticks(x, [str(x_i) for x_i in x])\n",
    "plt.savefig('output/hmm/combined_fractional_occupancy.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot mean life time - the time spent in a state before transitioning to a new state on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARATE\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "fig.suptitle('Mean Life Time')\n",
    "num_plots = len(decoded_state_sequences)\n",
    "subplot_idx = 1\n",
    "\n",
    "for (k, hmm_model, state_seq) in zip(all_subjects_all_trials_connectome_upper_triangular_flattened, hmm_models, decoded_state_sequences):\n",
    "\n",
    "    # Compute mean life time per state\n",
    "    mean_life_time_per_state = []\n",
    "    for state_id in range(0, hmm_model.means_.shape[0]):\n",
    "        \n",
    "        # Count number of transitions out of state with state_id\n",
    "        num_transitions_out_of_state_with_state_id = 0\n",
    "        for i in range(0, len(state_seq)-1):\n",
    "            if state_seq[i] == state_id and state_seq[i+1] != state_id:\n",
    "                num_transitions_out_of_state_with_state_id += 1\n",
    "        \n",
    "        # Count total number of time points spent in state with state id\n",
    "        num_time_points_in_state_with_state_id = len(state_seq[state_seq == state_id])\n",
    "        \n",
    "        # Compute mean life time\n",
    "        mean_life_time = num_time_points_in_state_with_state_id/num_transitions_out_of_state_with_state_id\n",
    "        mean_life_time_per_state.append(mean_life_time)\n",
    "    \n",
    "    \n",
    "    # Plot mean life time per state\n",
    "    fig.add_subplot(1, num_plots, subplot_idx)\n",
    "    plt.title(k)\n",
    "    x = np.arange(hmm_model.means_.shape[0])\n",
    "    plt.bar(x, height=mean_life_time_per_state)\n",
    "    plt.xticks(x, [str(x_i) for x_i in x])\n",
    "    subplot_idx += 1\n",
    "    \n",
    "plt.savefig('output/hmm/mean_life_time.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED\n",
    "# Compute mean life time per state\n",
    "mean_life_time_per_state = []\n",
    "for state_id in range(0, combined_modality_hmm_model.means_.shape[0]):\n",
    "\n",
    "    # Count number of transitions out of state with state_id\n",
    "    num_transitions_out_of_state_with_state_id = 0\n",
    "    for i in range(0, len(combined_modality_decoded_state_sequence)-1):\n",
    "        if combined_modality_decoded_state_sequence[i] == state_id and combined_modality_decoded_state_sequence[i+1] != state_id:\n",
    "            num_transitions_out_of_state_with_state_id += 1\n",
    "\n",
    "    # Count total number of time points spent in state with state id\n",
    "    num_time_points_in_state_with_state_id = len(combined_modality_decoded_state_sequence[combined_modality_decoded_state_sequence == state_id])\n",
    "\n",
    "    # Compute mean life time\n",
    "    mean_life_time = num_time_points_in_state_with_state_id/num_transitions_out_of_state_with_state_id\n",
    "    mean_life_time_per_state.append(mean_life_time)\n",
    "\n",
    "\n",
    "# Plot mean life time per state\n",
    "plt.title('Combined Mean Life Time')\n",
    "x = np.arange(combined_modality_hmm_model.means_.shape[0])\n",
    "plt.bar(x, height=mean_life_time_per_state)\n",
    "plt.xticks(x, [str(x_i) for x_i in x])\n",
    "\n",
    "plt.savefig('output/hmm/combined_mean_life_time.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot transition probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARATE - Transition Probabilities\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "fig.suptitle('Transition Probabilities')\n",
    "num_plots = len(hmm_models)\n",
    "subplot_idx = 1\n",
    "\n",
    "for (k, hmm_model) in zip(all_subjects_all_trials_connectome_upper_triangular_flattened, hmm_models):\n",
    "    \n",
    "    fig.add_subplot(1, num_plots, subplot_idx)\n",
    "    plt.imshow(hmm_model.transmat_, cmap='gist_heat')\n",
    "    plt.title(k)\n",
    "    plt.colorbar()\n",
    "    subplot_idx += 1\n",
    "\n",
    "plt.savefig('output/hmm/transition_probabilities.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINED - Transition Probabilities    \n",
    "plt.imshow(combined_modality_hmm_model.transmat_, cmap='gist_heat')\n",
    "plt.title('Combined Transition Probabilities')\n",
    "plt.colorbar()\n",
    "plt.savefig('output/hmm/combined_transition_probabilities.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot transitions between decoded states as a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_colors(n):\n",
    "    return [ cmx.rainbow(float(i)/n) for i in range(n) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate\n",
    "fig = plt.figure(figsize=(300, 25))\n",
    "fig.suptitle('Decoded Hidden State Sequences')\n",
    "\n",
    "num_plots = len(hmm_models)\n",
    "subplot_idx = 1\n",
    "\n",
    "for (k, hmm_model, state_seq) in zip(all_subjects_all_trials_connectome_upper_triangular_flattened, hmm_models, decoded_state_sequences):\n",
    "    \n",
    "    print(k)\n",
    "    fig.add_subplot(num_plots, 1, subplot_idx)\n",
    "    component_colors = get_n_colors(hmm_model.means_.shape[0])\n",
    "    x = 0\n",
    "    for state in state_seq[:6000]:\n",
    "        plt.axvline(x=x, color=component_colors[state])\n",
    "        x += 1\n",
    "        \n",
    "    plt.title(\"{0}\".format(k))\n",
    "    plt.yticks([])\n",
    "    subplot_idx += 1    \n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig('output/hmm/decoded_hidden_state_sequence.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined\n",
    "fig = plt.figure(figsize=(300, 5))\n",
    "\n",
    "component_colors = get_n_colors(combined_modality_hmm_model.means_.shape[0])\n",
    "x = 0\n",
    "for state in combined_modality_decoded_state_sequence[:6000]:\n",
    "    plt.axvline(x=x, color=component_colors[state])\n",
    "    x += 1\n",
    "\n",
    "plt.title(\"{0}\".format(\"Combined Decoded Hidden State Sequence\"))\n",
    "plt.yticks([])\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig('output/hmm/combined_decoded_hidden_state_sequence.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Graph Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    max_v = max(data)\n",
    "    min_v = min(data)\n",
    "    return (np.array(data) - min_v) / (max_v - min_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(len(all_subjects_all_trials_connectomes['fmri']))\n",
    "\n",
    "# The assortativity coefficient is a correlation coefficient between the strengths (weighted degrees) of all nodes\n",
    "# on two opposite ends of a link. A positive assortativity coefficient indicates that nodes tend to link to other\n",
    "# nodes with the same or similar strength.\n",
    "assortativity = []\n",
    "\n",
    "global_efficiency = []\n",
    "\n",
    "for time_pt in all_subjects_all_trials_connectomes['fmri'][:100]:\n",
    "    assortativity.append(bct.assortativity_wei(time_pt))  \n",
    "    global_efficiency.append(bct.efficiency_wei(time_pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t[:100], normalize(assortativity), color=\"red\", label=\"Assortativity\")\n",
    "plt.plot(t[:100], normalize(global_efficiency), color=\"blue\", label=\"Global Efficiency\")\n",
    "plt.legend()\n",
    "plt.savefig('output/hmm/graph_statistics_fmri.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize fMRI/EEG Connectome Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subject_id in ALL_SUBJECT_IDS:\n",
    "#     for trial_id in ALL_TRIAL_IDS:\n",
    "        \n",
    "#         # Attempt to load all connectome types\n",
    "#         connectomes = load_all_connectome_types(subject_id, trial_id,\n",
    "#                                                atlas='desikan', \n",
    "#                                                seconds_used_to_compute_fmri_connectome=60,\n",
    "#                                                exclude_bad_fmri_frames=True,\n",
    "#                                                filter_artifact_timepoints=True)\n",
    "        \n",
    "#         if connectomes is None:\n",
    "#             continue\n",
    "\n",
    "#         # Plot connectomes through time\n",
    "#         for t in range(0, connectomes['fmri'].shape[0]):\n",
    "            \n",
    "#             # Create figure and set title\n",
    "#             fig = plt.figure(figsize=(30, 35))\n",
    "#             fig.suptitle('Subject: \"{0}\" | Trial: {1} | Time: {2}'.format(subject_id, trial_id, t), fontsize=50)\n",
    "            \n",
    "#             # Plot connectomes\n",
    "#             subplot_idx = 1\n",
    "#             for connectome_id, connectome in connectomes.items():\n",
    "\n",
    "#                 ax = fig.add_subplot(len(connectomes), 2, subplot_idx)\n",
    "#                 plotting.plot_connectome(connectome[t], desikan_atlas_coordinates(), title='{0} Connectome'.format(connectome_id),\n",
    "#                                          edge_threshold='95%', node_size=20, colorbar=True, axes=ax)\n",
    "#                 subplot_idx += 1\n",
    "            \n",
    "#                 ax = fig.add_subplot(len(connectomes), 2, subplot_idx)\n",
    "#                 plotting.plot_matrix(connectome[t], vmin=-1., vmax=1., colorbar=True, axes=ax)\n",
    "#                 subplot_idx += 1\n",
    "    \n",
    "#             plt.savefig('output/connectomes_through_time/subject={0}_trial={1}_t={2}.png'.format(subject_id, trial_id, t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
